[["index.html", "Quantitative Ecology Modelling applications in population ecology Chapter 1 Prerequisites", " Quantitative Ecology Modelling applications in population ecology Matt Weldy 2021-02-22 Chapter 1 Prerequisites This is a sample book written in Markdown. You can use anything that Pandocs Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.org/tinytex/. "],["intro.html", "Chapter 2 Introduction", " Chapter 2 Introduction You can label chapter and section titles using {#label} after them, e.g., we can reference Chapter 2. If you do not manually label them, there will be automatic labels anyway, e.g., Chapter 4. Figures and tables with captions will be placed in figure and table environments, respectively. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 2.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 2.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 2.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 2.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2020) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). "],["abundance.html", "Chapter 3 Abundance 3.1 Conditional Likelihood", " Chapter 3 Abundance Here is a review of existing methods. 3.1 Conditional Likelihood Alho (1990) Huggins (1989) Huggins (1991) 3.1.1 Algebra \\[\\hat{N} = \\frac{M_{t+1}}{1-\\prod^{t}(1-p_t)}\\] \\[y_{i,t} \\sim Bernoulli(p_t) \\] 3.1.2 Simulation N &lt;- 150 #True population size n_occ &lt;- 4 #Number of trapping occasions p &lt;- 0.50 #Probability of first detection true_detections &lt;- array(NA, dim=c(N,n_occ)) for (t in 1:n_occ){ true_detections[,t] &lt;- rbinom(n=N,size=1,prob=p) } observed &lt;- true_detections[apply(true_detections,1,max) == 1,] MNKA &lt;- nrow(observed) print( paste0(&quot;Number ever detected: &quot;, MNKA,sep = &quot; &quot;) ) #number ever detected ## [1] &quot;Number ever detected: 138 &quot; 3.1.3 Models 3.1.3.1 JAGS library(R2jags) data &lt;- list( y=observed, nsites=nrow(observed), MNKA=MNKA, n_occ=n_occ ) modelstring &lt;- textConnection( &quot; model { # Likelihood for(i in 1:nsites) { # observation model for(j in 1:4) { y[i, j] ~ dbern(p) } } for(t in 1:4){ p_un[t] &lt;- (1-p) } # Priors p ~ dunif(0, 1) # Uninformative prior # Derived values N &lt;- (MNKA / (1-prod(p_un[]))) } &quot; ) parameters &lt;- c(&quot;p&quot;,&quot;N&quot;) inits &lt;- function() { list( ) } ni &lt;- 10000 ; nt &lt;- 1 ; nb &lt;- 5000 ; nc &lt;- 3 model &lt;- jags(data, inits, parameters, modelstring, n.chains = nc, n.thin = nt, n.iter = ni, n.burnin = nb) library(knitr) kable(round(model$BUGSoutput$summary[c(1,3),c(1,2,3,7,8,9)],2)) mean sd 2.5% 97.5% Rhat n.eff N 152.47 1.37 150.05 155.42 1 15000 p 0.53 0.02 0.49 0.57 1 15000 3.1.3.2 Stan library(rstan) data &lt;- list( y=observed, nsites=nrow(observed), MNKA=MNKA, n_occ=n_occ ) stan_model &lt;- &quot; data { int&lt;lower=0&gt; MNKA; int&lt;lower=0&gt; nsites; int&lt;lower=0&gt; n_occ; int&lt;lower=0,upper=1&gt; y[MNKA, n_occ]; } parameters { real&lt;lower=0, upper=1&gt; p; } model { for(i in 1:nsites) for(j in 1:4) y[i, j] ~ bernoulli_lpmf(p); } generated quantities { real N = MNKA / (1-(1-p)^4); } &quot; nc &lt;- 4 stan.samples &lt;- stan(model_code = stan_model, data = data, iter = 10000, chains = nc, cores = nc) library(knitr) kable(round(summary(stan.samples)$summary[c(2,1),c(1,2,3,4,8,10,9)],2)) mean se_mean sd 2.5% 97.5% Rhat n_eff N 152.46 0.02 1.39 150.04 155.45 1 7412.46 p 0.53 0.00 0.02 0.49 0.57 1 7340.89 3.1.4 Comparison {{&lt; tabs uniqueid &gt;}} {{&lt; tab JAGS &gt;}} Test &lt;- 1 {{&lt; /tab &gt;}} {{&lt; tab Stan &gt;}} Stan &lt;- code &lt;- 1 {{&lt; /tab &gt;}} {{&lt; tab Greta &gt;}} Greta &lt;- code &lt;- 1 {{&lt; /tab &gt;}} {{&lt; /tabs &gt;}} JAGS Stan Greta JAGS library(R2jags) data &lt;- list( y=observed, nsites=nrow(observed), MNKA=MNKA, n_occ=n_occ ) modelstring &lt;- textConnection( &quot; model { # Likelihood for(i in 1:nsites) { # observation model for(j in 1:4) { y[i, j] ~ dbern(p) } } for(t in 1:4){ p_un[t] &lt;- (1-p) } # Priors p ~ dunif(0, 1) # Uninformative prior # Derived values N &lt;- (MNKA / (1-prod(p_un[]))) } &quot; ) parameters &lt;- c(&quot;p&quot;,&quot;N&quot;) inits &lt;- function() { list( ) } ni &lt;- 10000 ; nt &lt;- 1 ; nb &lt;- 5000 ; nc &lt;- 3 model &lt;- jags(data, inits, parameters, modelstring, n.chains = nc, n.thin = nt, n.iter = ni, n.burnin = nb) ## Warning in jags.model(model.file, data = data, inits = init.values, n.chains = n.chains, : Unused variable &quot;n_occ&quot; in data ## Compiling model graph ## Resolving undeclared variables ## Allocating nodes ## Graph information: ## Observed stochastic nodes: 552 ## Unobserved stochastic nodes: 1 ## Total graph size: 562 ## ## Initializing model ## ## | | | 0% | |** | 4% | |**** | 8% | |****** | 12% | |******** | 16% | |********** | 20% | |************ | 24% | |************** | 28% | |**************** | 32% | |****************** | 36% | |******************** | 40% | |********************** | 44% | |************************ | 48% | |************************** | 52% | |**************************** | 56% | |****************************** | 60% | |******************************** | 64% | |********************************** | 68% | |************************************ | 72% | |************************************** | 76% | |**************************************** | 80% | |****************************************** | 84% | |******************************************** | 88% | |********************************************** | 92% | |************************************************ | 96% | |**************************************************| 100% library(knitr) kable(round(model$BUGSoutput$summary[c(1,3),c(1,2,3,7,8,9)],2)) mean sd 2.5% 97.5% Rhat n.eff N 146.50 1.57 143.76 149.92 1 15000 p 0.51 0.02 0.47 0.55 1 15000 Stan library(rstan) data &lt;- list( y=observed, nsites=nrow(observed), MNKA=MNKA, n_occ=n_occ ) stan_model &lt;- &quot; data { int&lt;lower=0&gt; MNKA; int&lt;lower=0&gt; nsites; int&lt;lower=0&gt; n_occ; int&lt;lower=0,upper=1&gt; y[MNKA, n_occ]; } parameters { real&lt;lower=0, upper=1&gt; p; } model { for(i in 1:nsites) for(j in 1:4) y[i, j] ~ bernoulli_lpmf(p); } generated quantities { real N = MNKA / (1-(1-p)^4); } &quot; nc &lt;- 4 stan.samples &lt;- stan(model_code = stan_model, data = data, iter = 10000, chains = nc, cores = nc, open_progress=FALSE) library(knitr) kable(round(summary(stan.samples)$summary[c(2,1),c(1,2,3,4,8,10,9)],2)) mean se_mean sd 2.5% 97.5% Rhat n_eff N 146.49 0.02 1.57 143.76 149.82 1 7269.96 p 0.51 0.00 0.02 0.47 0.55 1 7283.33 Greta Greta &lt;- code &lt;- 1 "],["methods.html", "Chapter 4 Methods", " Chapter 4 Methods We describe our methods in this chapter. "],["applications.html", "Chapter 5 Applications 5.1 Example one 5.2 Example two", " Chapter 5 Applications Some significant applications are demonstrated in this chapter. 5.1 Example one 5.2 Example two "],["final-words.html", "Chapter 6 Final Words", " Chapter 6 Final Words We have finished a nice book. "],["appendix-a.html", "A Appendix A A.1 Authors Guidelines", " A Appendix A A.1 Authors Guidelines We have decided to adapt the tidyverse style guide. Detailed content can be found here. tidyverse style guide Before committing code to the git repository, it should be styled using the styler package. Primary points are outlined below: - Use underscores to separate words in both variable and file names. File Names: chapter_1.Rmd --- Variable Names: observed_data When submitting a description of a new model use the template provided in Appendix B. However, if extenuating circumstances make the template in Appendix B untenable for a model, describe the reason for departure in the git commit message. Variables should be named with nouns, functions should be named with verbs Use dots to separate words in function names simulate.code &lt;- function(X) { } Label function arguments Spaces after commas not before Do not pad parentheses with spaces Pad operators with space foo == bar foo &lt;- bar foo + bar foo * bar "],["appendix-b.html", "B Appendix B B.1 Model Template", " B Appendix B B.1 Model Template ## Model Name Model description ### Algebra Algebraic model description in latex ### Simulation ```{r simulation} simulated_data &lt;- 1 ``` ### JAGS ```{r JAGS,warning=FALSE,message=FALSE,error=FALSE, results=&#39;hide&#39;,cache = TRUE} library(R2jags) data &lt;- list( ) model_string &lt;- textConnection( &quot; model { # Likelihood # Priors # Derived values } &quot; ) parameters &lt;- c( ) set_initial_value &lt;- function() { list( ) } ni &lt;- 10000 ; nt &lt;- 1 ; nb &lt;- 5000 ; nc &lt;- 3 model &lt;- jags(data, set_initial_value, parameters, model_string, n.chains = nc, n.thin = nt, n.iter = ni, n.burnin = nb) ``` ```{r output_jags_table} library(knitr) kable(round( ,2)) ``` ### Stan ```{r stan_model_fit ,warning=FALSE,message=FALSE,error=FALSE, results=&#39;hide&#39;,cache = TRUE} library(rstan) data &lt;- list( ) stan_model &lt;- &quot; data { } parameters { } model { } generated quantities { } &quot; nc &lt;- 4 stan.samples &lt;- stan(model_code = stan_model, data = data, iter = 10000, chains = nc, cores = nc) ``` ```{r output_stan_table} library(knitr) kable(round( ,2)) ``` ### Comparison ```{r Comparison} ``` "],["references.html", "References", " References Alho, J. M. 1990. Logistic Regression in CaptureRecapture Models. Biometrics 46 (3): 62335. Huggins, R. M. 1989. On the Statistical Analysis of Capture Experiments. Biometrika 76 (1): 13340. https://doi.org/10.2307/2336377. . 1991. Some Practical Aspects of a Conditional Likelihood Approach to Capture Experiments. Biometrics 47 (2): 72532. https://doi.org/10.2307/2532158. Xie, Yihui. 2015. Dynamic Documents with R and Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. http://yihui.org/knitr/. . 2020. Bookdown: Authoring Books and Technical Documents with r Markdown. https://github.com/rstudio/bookdown. "]]
